<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Array sum - holozoo</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">holozoo</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="calculating-array-sum-with-speed-of-l1-cache"><a class="header" href="#calculating-array-sum-with-speed-of-l1-cache">Calculating array sum with speed of L1 cache</a></h1>
<h2 id="problem-statement"><a class="header" href="#problem-statement">Problem statement</a></h2>
<p>Calculate sum of array of numbers. Datatype can be either of <code>int32_t</code>, <code>int64_t</code>, <code>float</code>, <code>double</code>.
Do this on x86-64. Do it as fast as possible.
Array size can be arbitrary, but in range 1024-16384.</p>
<h2 id="tldr"><a class="header" href="#tldr">TLDR</a></h2>
<ul>
<li>Use AVX-512</li>
<li>Use as much accumulator variables as possible</li>
</ul>
<h2 id="in-search-of-fastest-code"><a class="header" href="#in-search-of-fastest-code">In search of fastest code</a></h2>
<h3 id="naive-solution"><a class="header" href="#naive-solution">Naive solution</a></h3>
<pre><code class="language-cpp">float sum(size_t count, const float *data) {
    float accum = 0;
    for (size_t i = 0; i &lt; count; ++i)
        accum += data[i];
    return accum;
}
</code></pre>
<h4 id="gcc"><a class="header" href="#gcc">GCC</a></h4>
<p>If we compile with <code>gcc -O2</code>, we got the following code in main loop.
It has two additions to the <code>xmm0</code> register, which serves as sum accumulator.
Notice that there are two additions: GCC decided to unroll the loop to process 2 elements per iteration.</p>
<pre><code class="language-x86asm">.L3:
        vaddss  xmm0, xmm0, DWORD PTR [rsi]
        add     rsi, 8
        vaddss  xmm0, xmm0, DWORD PTR [rsi-4]
        cmp     rsi, rax
        jne     .L3
</code></pre>
<h4 id="clang"><a class="header" href="#clang">Clang</a></h4>
<p>However, if we compile with <code>clang -O2</code>, we get the following loop:</p>
<pre><code class="language-x86asm">.LBB0_9:
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 4]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 8]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 12]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 16]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 20]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 24]
        vaddss  xmm0, xmm0, dword ptr [rsi + 4*rcx + 28]
        add     rcx, 8
        cmp     rdi, rcx
        jne     .LBB0_9
</code></pre>
<p>Clang unrolls loop to process 8 items per iteration.</p>
<h4 id="comparison"><a class="header" href="#comparison">Comparison</a></h4>
<p>Let's plug this code into <a href="uica.uops.info">UICA</a> to calculate loop throughput.</p>
<p>GCC:</p>
<pre><code>Throughput (in cycles per iteration): 8.00
Bottleneck: Dependencies

The following throughputs could be achieved if the given property were the only bottleneck:

  - DSB: 1.00
  - Issue: 1.00
  - Ports: 1.00
  - Dependencies: 8.00
</code></pre>
<p>Clang:</p>
<pre><code>Throughput (in cycles per iteration): 32.00
Bottleneck: Dependencies

The following throughputs could be achieved if the given property were the only bottleneck:

  - DSB: 1.67
  - Issue: 4.50
  - Ports: 4.00
  - Dependencies: 32.00
</code></pre>
<p>GCC has predicted throughput of 8 cycles/iteration. It processes 2 * 4 = 8 bytes/iteration. So, it processes 1 byte/cycle.</p>
<p>Clang has predicated throughput of 32 cycles/iteration. It processes 8 * 4 = 32 bytes/iteration. So, it processes 1 byte/cycle.</p>
<p>The throughput is the same.</p>
<p>We can plug the code that does not unroll the loop, and see that we would get the same 1 byte/cycle.</p>
<p>What's the deal here?
UICA tells us in the second line:</p>
<pre><code>Bottleneck: Dependencies
</code></pre>
<p>Modern CPUs are pipelined, and multiple iterations of loop can be running simultaneously. That works if they do not have data dependencies (also called <a href="https://en.wikipedia.org/wiki/Hazard_(computer_architecture)">data hazards</a>).</p>
<p>UICA provides us with pipeline view. We can see that each next addition cannot execute <code>E</code> until previous finished running (this is indicated by <code>D</code> - dependency).
So, loop unrolling does not matter because all the additions are waiting on the same register to be updated.
<img src="simd/image.png" alt="alt text" /></p>
<h4 id="improving-compiler-result"><a class="header" href="#improving-compiler-result">Improving compiler result</a></h4>
<p>We see that both GCC and Clang generate code that adds all array elements to a single accumulator sequentially.
This happens because compilers assume that floating-point addition is not commutative (a + b != b + a for any a, b) under the IEEE standard.
Compilers have option <code>-ffast-math</code> to relax this a bit.</p>
<blockquote>
<p>Programs compiled with <code>-ffast-math</code> can produce results different from naive solution, and often much less precise. This is not our concern, since we try to do summation as fast as possible. But to do correct summation there are techniques like <a href="https://en.wikipedia.org/wiki/Pairwise_summation">Pairwise summation</a> used, for example, in <a href="https://github.com/apache/arrow/blob/37f62d0bc5f4d22e7194947963b445225b984558/cpp/src/arrow/compute/kernels/aggregate_internal.h#L144">Apache Arrow</a>.</p>
</blockquote>
<h4 id="gcc-1"><a class="header" href="#gcc-1">GCC</a></h4>
<p>Compiling the code using GCC with <code>-ffast-math</code> we get the same result.</p>
<blockquote>
<p>We could get GCC to generate better code with <code>-funroll-loops</code> and <code>-fvariable-expansion-in-unroller</code> flags (But if compilers were any good at their job we would have no need in these flags).</p>
</blockquote>
<h4 id="clang-1"><a class="header" href="#clang-1">Clang</a></h4>
<p>Compiling the code using Clang with <code>-ffast-math</code> we get the following code:</p>
<pre><code class="language-x86asm">.LBB0_5:
        vaddps  ymm0, ymm0, ymmword ptr [rsi + 4*rcx]
        vaddps  ymm1, ymm1, ymmword ptr [rsi + 4*rcx + 32]
        vaddps  ymm2, ymm2, ymmword ptr [rsi + 4*rcx + 64]
        vaddps  ymm3, ymm3, ymmword ptr [rsi + 4*rcx + 96]
        add     rcx, 32
        cmp     rax, rcx
        jne     .LBB0_5
</code></pre>
<p>First thing to notice is that Clang generates code using <code>ymm</code> registers coming from <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> instruction set.
Secondly, it uses <code>ps</code> versions of addition - adding together <code>packed scalars</code>. Each <code>vaddps</code> instruction adds together 8 float values in parallel.
We can see that clang reduced the unroll count to 4 (previously being 8), and uses 4 distinct accumulators.
In the function epilogue these accumulators are added together to produce the final result.</p>
<p>What UICA tells us about this code?</p>
<pre><code class="language-x86asm">Throughput (in cycles per iteration): 4.02
Bottleneck: Dependencies

The following throughputs could be achieved if the given property were the only bottleneck:

  - LSD: 1.33
  - Issue: 2.00
  - Ports: 2.00
  - Dependencies: 4.00
</code></pre>
<p><img src="simd/image-1.png" alt="alt text" /></p>
<blockquote>
<p>Notice that UICA still tells us that this code is dependency-bound</p>
</blockquote>
<p>Code has predicated throughput of 4 cycles/iteration. It processes 8 * 4 * 4 = 128 bytes/iteration. So, it processes 32 bytes/cycle.
This is 32 times more than previous version!</p>
<h3 id="manual-vectorization"><a class="header" href="#manual-vectorization">Manual vectorization</a></h3>
<p>What we got as result from investigating compiler output is actually obvious (or becomes obvious, if you spend too much free time on problems like this):</p>
<ul>
<li>If you want to compute faster, use SIMD instructions.</li>
<li>Use more accumulators to remove data dependencies.</li>
</ul>
<p>This is manually vectorized addition loop, using SIMD instructions from AVX instruction set:</p>
<pre><code class="language-cpp">double hsum_double_avx(__m256d v) 
{
    __m128d vlow  = _mm256_castpd256_pd128(v);
    __m128d vhigh = _mm256_extractf128_pd(v, 1); // high 128
            vlow  = _mm_add_pd(vlow, vhigh);     // reduce down to 128
    __m128d high64 = _mm_unpackhi_pd(vlow, vlow);
    return  _mm_cvtsd_f64(_mm_add_sd(vlow, high64));  // reduce to scalar
}

double f64_arr_sum_w4(const double *arr, int count)
{
    double sum = 0.0;
    __m256d accum0 = _mm256_setzero_pd();
    for (int i = 0; i &lt; count - 3; i += 4) {
        __m256d v0 = _mm256_load_pd(&amp;arr[i]);
        accum0 = _mm256_add_pd(accum0, v0);
    } 
    sum = hsum_double_avx(accum0);
    return sum;
}
</code></pre>
<blockquote>
<p>What is happening in <code>hsum_double_avx</code> is not very important. You can read more about the function used <a href="https://stackoverflow.com/questions/49941645/get-sum-of-values-stored-in-m256d-with-sse-avx">in this StackOverflow answer</a>.</p>
</blockquote>
<p>If we use 4 accumulators here, and add them up in the end, we would get pretty much the same code as clang generates.</p>
<p>The question becomes, how many accumulators should we use?</p>
<p>I wrote the this function for all datatypes of interest (<code>int32_t</code>, <code>int64_t</code>, <code>float</code>, <code>double</code>), with accumulator count varying from 1 to 16 (as there are 16 ymm registers, and 32 zmm registers with AVX-512).
I did this using AVX and AVX-512 instructions.</p>
<h4 id="benchmarks"><a class="header" href="#benchmarks">Benchmarks</a></h4>
<p>These are results of benchmarks done using <a href="https://github.com/google/benchmark">google benchmark</a>.
I used a machine with <a href="https://en.wikichip.org/wiki/intel/microarchitectures/cascade_lake">Cascade Lake</a> CPU.
Cascade Lake has good support of AVX-512 and does not suffer from underclocking as much as Skylake-based CPUs did.
I used array size of 1024.</p>
<p><code>double</code>:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>1 acc</th><th>2 acc</th><th>4 acc</th><th>8 acc</th><th>16 acc</th></tr></thead><tbody>
<tr><td>AVX2</td><td>259ns</td><td>160ns</td><td>87ns</td><td>56ns</td><td>56ns</td></tr>
<tr><td>AVX512</td><td>131ns</td><td>88ns</td><td>60ns</td><td>57ns</td><td></td></tr>
</tbody></table>
</div>
<p><code>float</code>:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>1 acc</th><th>2 acc</th><th>4 acc</th><th>8 acc</th><th>16 acc</th></tr></thead><tbody>
<tr><td>AVX2</td><td>103ns</td><td>69ns</td><td>39ns</td><td>31ns</td><td>31ns</td></tr>
<tr><td>AVX512</td><td>64ns</td><td>44ns</td><td>34ns</td><td>31ns</td><td></td></tr>
</tbody></table>
</div>
<p><code>int64_t</code>:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>1 acc</th><th>2 acc</th><th>4 acc</th><th>8 acc</th></tr></thead><tbody>
<tr><td>AVX2</td><td>80ns</td><td>74ns</td><td>74ns</td><td></td></tr>
<tr><td>AVX512</td><td>51ns</td><td>50ns</td><td>47ns</td><td>47ns</td></tr>
</tbody></table>
</div>
<p><code>int32_t</code>:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>1 acc</th><th>2 acc</th><th>4 acc</th><th>8 acc</th></tr></thead><tbody>
<tr><td>AVX2</td><td>131ns</td><td>81ns</td><td>81ns</td><td></td></tr>
<tr><td>AVX512</td><td>36ns</td><td>21ns</td><td>22ns</td><td>23ns</td></tr>
</tbody></table>
</div>
<h4 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h4>
<p>AVX-512 is superior in speed. Always.
AVX-512 instructions take the same time to decode and execute, but are able to process more elements, as well as remove pressure from memory subsystem, issuing less requests.</p>
<p>We can see that all datatypes converge to the same time as number of accumulators increases. We can say that speed does not degrades with greater accumulator count, but it stops improving from certain point either.
We can also see that using 8 accumulators for doing sum of <code>float</code> array using AVX (what we did in first part of post) is faster with 8 accumulators, than with 4 (as clang generated). But this difference is unimportant.
UICA would say that using 8 accumulators instead of 4 would provide twice the throughput, but it is clearly not the case.</p>
<blockquote>
<p>One of the things I noted for myself - is that throughput predictors are unable to handle throughput-bound problems like this well. It only provides approximate results, and sometimes outright incorrect.</p>
</blockquote>
<p>The most important question here - what is the limit? Why code stops getting faster?</p>
<p>We can try to guess. Let's calculate the time throughput for <code>double</code> and <code>float</code> sums using AVX-512.
They take 56 and 31 ns respectively. They process 8 * 1024 = 8192 and 4 * 1024 = 4096 bytes respectively.
This is 146 bytes/ns and 132 bytes/ns throughput. This is about 140 GB/s.</p>
<p>This sounds like a lot. We can checks <a href="https://travisdowns.github.io/blog/2019/06/11/speed-limits.html">Performance speed limits</a>, or just google - what is the speed of memory for fastest access.
Array data is accessed through L1 cache. L1 on Cascade Lake works 64 bytes/per cycle.
Knowing that our CPU operates at about 3GHz, we get 182 GB/s of maximum possible throughput.</p>
<p>Our code hit the L1 cache speed limit - it can't get any faster. This means that we process data faster than we read it, so, as I see it, this is satisfactory result.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="simd/8bits_8bytes.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

                    <a rel="next prefetch" href="simd/8bits_8bytes.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
